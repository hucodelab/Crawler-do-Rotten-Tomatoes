{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install psycopg2\n",
    "# !pip install google-cloud-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #@markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
    "\n",
    "# # Please fill in these values.\n",
    "# project_id = \"digital-display-376201\" #@param {type:\"string\"}\n",
    "\n",
    "# # Quick input validations.\n",
    "# assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n",
    "\n",
    "# # Configure gcloud.\n",
    "# !gcloud config set project {project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud.sql.connector import Connector\n",
    "# import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-c16ba3ec765d>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('path/chromedriver')\n"
     ]
    }
   ],
   "source": [
    "# preparamos o driver do Chrome\n",
    "driver = webdriver.Chrome('path/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 2CDA-BFF4\n",
      "\n",
      " Directory of C:\\Users\\Ernesto\\OneDrive - usp.br\\Turing USP\\DS\\data_engineering\\crawler\n",
      "\n",
      "02/28/2023  08:50 PM    <DIR>          .\n",
      "02/28/2023  08:50 PM    <DIR>          ..\n",
      "12/11/2022  11:15 AM    <DIR>          .ipynb_checkpoints\n",
      "10/19/2022  06:46 PM        12,188,160 chromedriver.exe\n",
      "11/22/2022  04:22 PM         6,776,586 chromedriver_win32.zip\n",
      "01/31/2023  12:23 AM    <DIR>          data_input\n",
      "02/28/2023  12:57 AM    <DIR>          data_output\n",
      "11/22/2022  07:06 PM           560,484 foo.png\n",
      "02/28/2023  12:17 AM         4,523,105 parte00.csv\n",
      "02/28/2023  12:17 AM         4,608,220 parte01.csv\n",
      "02/28/2023  12:17 AM         4,644,078 parte02.csv\n",
      "02/28/2023  12:17 AM         4,656,313 parte03.csv\n",
      "02/28/2023  12:17 AM         4,667,530 parte04.csv\n",
      "02/28/2023  12:17 AM         4,695,746 parte05.csv\n",
      "02/28/2023  12:17 AM         4,668,593 parte06.csv\n",
      "02/28/2023  12:17 AM         4,660,944 parte07.csv\n",
      "02/28/2023  12:17 AM         4,651,497 parte08.csv\n",
      "02/28/2023  12:17 AM         4,643,068 parte09.csv\n",
      "02/28/2023  12:17 AM         4,648,888 parte10.csv\n",
      "02/28/2023  12:17 AM         4,630,710 parte11.csv\n",
      "02/28/2023  12:17 AM         4,639,228 parte12.csv\n",
      "02/28/2023  12:17 AM         4,679,570 parte13.csv\n",
      "02/28/2023  12:17 AM         4,654,985 parte14.csv\n",
      "02/28/2023  12:17 AM         4,660,899 parte15.csv\n",
      "02/28/2023  12:17 AM         4,612,580 parte16.csv\n",
      "02/28/2023  12:17 AM         4,647,841 parte17.csv\n",
      "02/28/2023  12:17 AM         4,654,655 parte18.csv\n",
      "02/28/2023  12:17 AM         4,675,533 parte19.csv\n",
      "02/28/2023  12:17 AM         2,880,926 parte20.csv\n",
      "11/22/2022  09:24 PM            16,118 rotten_tomatoes.ipynb\n",
      "12/04/2022  12:41 PM            61,938 rotten_tomatoes_2.ipynb\n",
      "12/04/2022  03:10 PM            27,053 rotten_tomatoes_3.ipynb\n",
      "12/06/2022  03:52 AM            89,053 rotten_tomatoes_4.ipynb\n",
      "02/28/2023  08:50 PM            43,181 rotten_tomatoes_by_names.ipynb\n",
      "11/22/2022  08:35 PM           227,803 scrapper_rotten_tomatoes_herm.ipynb\n",
      "12/06/2022  01:06 AM           973,346 test\n",
      "12/11/2022  11:14 AM    <DIR>          TMDB\n",
      "12/11/2022  11:13 AM           139,959 TMDB_API\n",
      "12/11/2022  12:09 PM           129,708 TMDB_API.ipynb\n",
      "              33 File(s)    117,038,298 bytes\n",
      "               6 Dir(s)  13,982,466,048 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'parte00.csv'\n",
    "# file = 'data_output/ztrending_movies.csv'\n",
    "\n",
    "df0 = pd.read_csv(file, header=None).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.join(df0[1].apply(json.loads).apply(pd.Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.loc[:,['id','original_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df0.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criacao do dataset com os dados do Rotten Tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos esta funcao para que os nomes dos filmes sejam transformados nos nomes dos filmes da url\n",
    "# exemplo: The Matrix ---> the_matrix, desta forma conseguimos acessar as urls\n",
    "\n",
    "def rottenize(title):\n",
    "    '''\n",
    "    Esta funcao sustitui os carateres por vazio ou por _\n",
    "    para depois entrar nos links (urls) dos filmes no rotten\n",
    "    '''\n",
    "    title = title.translate(str.maketrans({':': '', \"'\": '', \".\":\"\", \",\":\"\", \n",
    "                                          \"-\":\"_\", \" \":\"_\"}))\n",
    "    \n",
    "    return title.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos uma lista vazia para armazenar as urls dos filmes do dataset do TMDB\n",
    "links = []\n",
    "for tit in df0['original_title'].apply(rottenize):\n",
    "    links.append('https://www.rottentomatoes.com/m/{}'.format(tit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas para armazenar a informacao\n",
    "tmdb_id = []\n",
    "\n",
    "nomes = []\n",
    "TOMATOMETER = []\n",
    "TOMATOMETER_rev = []\n",
    "aud_scr = []\n",
    "aud_scr_rev = []\n",
    "main6 = []\n",
    "main7 = []\n",
    "main8 = []\n",
    "main9 = []\n",
    "\n",
    "genre = []\n",
    "language = []\n",
    "director = []\n",
    "producer = []\n",
    "writer = []\n",
    "rel_date_th = []\n",
    "rel_date_stream = []\n",
    "box = []\n",
    "runtime = []\n",
    "distributor = []\n",
    "description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name[0], name[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 1\n",
    "# driver.get(links[j])\n",
    "\n",
    "# # se aparecer algun erro no navegador voltamos ao comeco do loop\n",
    "\n",
    "# # informacoes da descricao do filme\n",
    "# info_we = driver.find_elements(By.CLASS_NAME, \"media-body\")\n",
    "# # informações mais breves da descricao\n",
    "# short_info = info_we[0].text.split('\\n')[2:]\n",
    "\n",
    "# # informacoes principais do filme: nome, scores e quantidade de reviews\n",
    "# info_main = driver.find_elements(By.CLASS_NAME, \"thumbnail-scoreboard-wrap\")\n",
    "# info_main = info_main[0].text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionamos um pedaco da lista de links de filmes comencando pelo \"start\"\n",
    "# links = links[start:]\n",
    "\n",
    "def create_df(n):\n",
    "    '''\n",
    "    n: numero de filmes a coletar\n",
    "    '''  \n",
    "    # neste dataset iremos armazenar as informacoes extraidas do Rotten Tomatoes\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for j in range(len(links[:n])):\n",
    "        \n",
    "        # mostra quantos filmes ja varreu\n",
    "        print(j, end=\"\\r\", flush=True)\n",
    "        \n",
    "        # entramos no site do filme\n",
    "        driver.get(links[j])\n",
    "        \n",
    "        # se aparecer algun erro no navegador voltamos ao comeco do loop\n",
    "        try:\n",
    "            # informacoes da descricao do filme\n",
    "            info_we = driver.find_elements(By.CLASS_NAME, \"media-body\")\n",
    "            # informações mais breves da descricao\n",
    "            short_info = info_we[0].text.split('\\n')[2:]\n",
    "\n",
    "            # informacoes principais do filme: nome, scores e quantidade de reviews\n",
    "            info_main = driver.find_elements(By.CLASS_NAME, \"thumbnail-scoreboard-wrap\")\n",
    "            info_main = info_main[0].text.split('\\n')\n",
    "\n",
    "            # dicionario para armazenar as infos do filme\n",
    "            short_info_dic = dict()\n",
    "\n",
    "            # acrescentamos tambem as informacoes principais\n",
    "            short_info_dic['Nome'] = info_main[0]\n",
    "            short_info_dic['TOMATOMETER'] = info_main[2]\n",
    "            short_info_dic['TOMATOMETER reviews'] = info_main[4]\n",
    "            short_info_dic['AUDIENCE SCORE'] = info_main[5]\n",
    "            short_info_dic['AUDIENCE SCORE reviews'] = info_main[7]\n",
    "            \n",
    "            # colunas auxiliares\n",
    "            short_info_dic['main6'] = info_main[1]\n",
    "            short_info_dic['main7'] = info_main[3]\n",
    "            short_info_dic['main8'] = info_main[6]\n",
    "            \n",
    "            try:\n",
    "                short_info_dic['main9'] = info_main[8]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # informacoes breves do filme\n",
    "        for i in range(len(short_info)):\n",
    "            infos = short_info[i].split(': ')\n",
    "            try:\n",
    "                short_info_dic[infos[0]] = infos[1]\n",
    "            except:\n",
    "                short_info_dic[infos[0]] = np.nan\n",
    "\n",
    "        # resumo e descricao do filme\n",
    "        short_info_dic[info_we[0].text.split('\\n')[0]] = info_we[0].text.split('\\n')[1]\n",
    "\n",
    "        # colocamos as informacoes nas listas\n",
    "        try:\n",
    "            nomes.append(short_info_dic['Nome'])\n",
    "            tmdb_id.append(df0.loc[[j],['id']].values[0][0])\n",
    "        except:\n",
    "            nomes.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            TOMATOMETER.append(short_info_dic['TOMATOMETER'])\n",
    "        except:\n",
    "            TOMATOMETER.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            TOMATOMETER_rev.append(short_info_dic['TOMATOMETER reviews'])\n",
    "        except:\n",
    "            TOMATOMETER_rev.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            aud_scr.append(short_info_dic['AUDIENCE SCORE'])\n",
    "        except:\n",
    "            aud_scr.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            main6.append(short_info_dic['main6'])\n",
    "        except:\n",
    "            main6.append(np.nan)\n",
    "            \n",
    "        try:\n",
    "            main7.append(short_info_dic['main7'])\n",
    "        except:\n",
    "            main7.append(np.nan)\n",
    "            \n",
    "        try:\n",
    "            main8.append(short_info_dic['main8'])\n",
    "        except:\n",
    "            main8.append(np.nan)\n",
    "            \n",
    "        try:\n",
    "            main9.append(short_info_dic['main9'])\n",
    "        except:\n",
    "            main9.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            aud_scr_rev.append(short_info_dic['AUDIENCE SCORE reviews'])\n",
    "        except:\n",
    "            aud_scr_rev.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            genre.append(short_info_dic['Genre'])\n",
    "        except:\n",
    "            genre.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            language.append(short_info_dic['Original Language'])\n",
    "        except:\n",
    "            language.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            director.append(short_info_dic['Director'])\n",
    "        except:\n",
    "            director.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            producer.append(short_info_dic['Producer'])\n",
    "        except:\n",
    "            producer.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            writer.append(short_info_dic['Writer'])\n",
    "        except:\n",
    "            writer.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            rel_date_th.append(short_info_dic['Release Date (Theaters)'])\n",
    "        except:\n",
    "            rel_date_th.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            rel_date_stream.append(short_info_dic['Release Date (Streaming)'])\n",
    "        except:\n",
    "            rel_date_stream.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            box.append(short_info_dic['Box Office (Gross USA)'])\n",
    "        except:\n",
    "            box.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            runtime.append(short_info_dic['Runtime'])\n",
    "        except:\n",
    "            runtime.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            distributor.append(short_info_dic['Distributor'])\n",
    "        except:\n",
    "            distributor.append(np.nan)\n",
    "            \n",
    "        try:\n",
    "            description.append(short_info_dic['MOVIE INFO'])\n",
    "        except:\n",
    "            description.append(np.nan)\n",
    "            \n",
    "    # Alimentamos o database\n",
    "\n",
    "    df = pd.DataFrame() \n",
    "\n",
    "    df['tmdb_id'] = tmdb_id\n",
    "#     df['Movie Name'] = nomes\n",
    "    df['tomatometer_reviews'] = aud_scr\n",
    "#     df['AUDIENCE SCORE reviews'] = aud_scr_rev\n",
    "    # mudou a estrutura do site, entao algumas listas das q foram criadas inicialmente\n",
    "    # nao coincidem com o nome da coluna\n",
    "    df['genre_year'] = TOMATOMETER\n",
    "#     df['TOMATOMETER reviews'] = nomes\n",
    "\n",
    "    df['movie_name'] = main6\n",
    "    df['tomatometer_score'] = main7\n",
    "    df['audience_score'] = main8\n",
    "    df['audience_reviews'] = main9\n",
    "    \n",
    "    df['Genre'] = genre\n",
    "    df['Original Language'] = language\n",
    "    df['Director'] = director\n",
    "    df['Producer'] = producer\n",
    "    df['Writer'] = writer\n",
    "    df['Release Date (Theaters)'] = rel_date_th\n",
    "    df['Release Date (Streaming)'] = rel_date_stream\n",
    "    df['box office'] = box\n",
    "    df['Runtime'] = runtime\n",
    "    df['Distributor'] = distributor\n",
    "    df['MOVIE INFO'] = description\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # conexao com o database do GCP\n",
    "# con = psycopg2.connect(host='104.154.213.9' , database='turing_de',\n",
    "# user = 'postgres', password='pwd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\r"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "df = create_df(len(links))\n",
    "# df = create_df(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data_output/Rotten_2021_4000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @timeit\n",
    "\n",
    "# df.to_csv(\"data_output/Rotten_2021_4000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"data_output/Rotten_2021_4000.csv\").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrar por lingua e por ano"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
